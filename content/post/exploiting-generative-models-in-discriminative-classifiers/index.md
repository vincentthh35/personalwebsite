---
title: "[Paper Notes] Exploiting Generative Models in Discriminative Classifiers"
slug: "Exploiting Generative Models in Discriminative Classifiers"
date: 2021-03-15T18:29:02+08:00
categories:
-   Paper-Notes
-   aMMAI
draft: false
author: "謝宗晅"
---

論文網址：\
[Exploiting Generative Models in Discriminative Classifiers](https://papers.nips.cc/paper/1998/file/db1915052d15f7815c8b88e879465a1e-Paper.pdf)

### 概述

這篇論文的最大貢獻是將 generative model 的優勢和 discriminative model 結合，促成了之後非常多很棒的 work（例如 VLAD）。

### 前情提要

這個部份要比較一下 generative model 和 discriminative model 的優缺點。

---

Generative model 想達成的目標是得到「資料的產生機制」，也就是 $P(X, Y)$，所以我們可以透過 $P(X) =\sum_{y} P(X, Y=y)$ 來得到 $P(Y|X) = P(X, Y) / P(X)$ 來做到和 discriminative model 一樣的事情，也就是知道 $x$ 的 label 是哪一種的機率最高。

Generative model 的優點：因為我們有了一個 distribution，所以我們可以產生出沒有觀察到的資料；還有因為我們得到的是 distribution，所以我們就可以處理不定長度的 data（例如 hidden markov model），所以 generative model 最大的優勢在於不只可以做 classification，還可以有其他的功能。

Generative model 的缺點：在大部分的情況之下，classification 做的並沒有 discriminative model 來的好。

---

Discriminative model 想達成的目標比較直觀，就是直接得到 $P(Y|X)$，也就是給定一個 $X$，它的 label 是哪一個的機率最高。Discriminative model 完全不管資料的產生機制為何，目的只是要分出不同 label 的資料之間的分界。

Discriminative model 的優點：在 classification 上表現比較好，並且作法也比較直觀（不用再經由貝氏機率論來得到結果）。

Discriminative model 的缺點：難以用來處理不定長 input 的問題（例如 DNA 序列）。

### 內容

這篇論文提出了 Fisher kernel，概念是取自於 Fisher score，再把 Fisher score 和 kernel function 串聯在一起而變成 Fisher kernel。

Fisher score 其實就是 log likelihood function 的 gradient：
{{< math >}}$$U_X = \nabla_\theta \log P(X|\theta)$${{< /math >}}
可以想像 $U_X$ 代表的是將 $X$ 投影到 manifold $M_{\Theta}$ 的 gradient space（其實就是某種 feature space）。

Fisher information matrix，期望值是 $P(X|\theta)$ 的期望值：
{{< math >}}$$I = \mathbb E_X[U_XU^T_X]$${{< /math >}}

Fisher kernel：
{{< math >}}$$K(X_i, X_j) = \phi^T_{X_i}I\phi_{X_j} = U^T_{X_i}I^{-1}U_{X_j}$${{< /math >}}

本篇論文提出了 Fisher kernel，我個人認為最大的賣點是能將不定維度的 vector 轉化成一個固定維度的 feature，如果沒有這樣的 kernel，對影像處理使用 bag of words 的方法將會因為維度太大並且 feature vector 太過於 sparse，而使得學習的效率大大降低，藉由 Fisher kernel 就可以大大減低高維度所造成的不便。

### Contributions

* 一次囊括了 generative model 和 discriminative model 的優勢：
    * generative model：可以產生額外的資料，並且可以用來處理**不定維度的 vectors**（例如 SIFT）
    * discriminative model：以分類來說，做的比 discriminative model 還要好
* 之後的 VLAD 是以 Fisher kernel 作為元素之一
    * VLAD 是 non-deep-based 的方法中表現最好的之一

### Other References

* https://jaketae.github.io/study/fisher/
* https://en.wikipedia.org/wiki/Generative_model
